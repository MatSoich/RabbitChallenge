<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[['\$','\$'],['\\(','\\)']],processEscapes:true},CommonHTML: {matchFontHeight:false}});</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

13 CTC
==========

# 音声認識タスク

- 音声認識(ASR: Automatic Speech Recognition)とは、入力信号を音声特徴ベクトルに変換、その音声特徴ベクトルの系列から対応する単語列を推定するタスクです。
- まず、入力された音声信号を認識処理にとって都合の良い表現に変換します。この処理のことを特徴量抽出と呼びます。主にフーリエ変換などが実施される。
- 次に、認識の部分で音声認識結果の候補の確率を計算します。（音声認識モデル）
- 現在の音声認識モデルは音響モデル、発音辞書、言語モデルの3つの部分から構成されており、それぞれ以下の役割を担っています。
  - 音響モデル
    - 音声特徴量と音素列の間の確率を計算するモデル。
  - 発音辞書
    - 音素列と単語との対応を扱うモデル。
  - 言語モデル
    - ある単語に対して、その単語が発話される確率を計算します。
- 音響モデルについては、1980年代から2010年ごろまでの長い間、隠れマルコフモデル(HMM: hidden Markov model)と混合正規分布(GMM: Gaussian mixture model)と呼ばれるモデルを組み合わせることでモデル化されていました。それが2010年ごろから深層学習技術の発展に伴い、混合正規分布がディープニューラルネットワーク(DNN: Deep Neural Network)に置き換わることで音声認識精度が飛躍的に向上し、多くの製品で使われる音声認識モデルとなっています。
- 1つ大きな問題があります。それは直感的には非常に理解しやすい構造なのですが、実際に実装する際には非常に複雑になってしまう点です。特に、3つのモジュールの出力をうまく統合して音声認識結果を出力する「デコーダ」と呼ばれる処理部分の実装が難しく、音声認識モデルを実装する上で高いハードル
- 2015年ごろからは音響モデル、発音辞書、言語モデルを1つのDNNで表現する、いわゆるEnd-to-Endモデル(E2Eモデル)の研究が盛ん
  - その一つがCTC

# CTC

- End-to-Endモデルの中でも比較的初期に提案されたモデル
- 従来手法のような隠れマルコフモデル(HMM)を使用せずにDNNだけで音響モデルを構築する手法として提案された
  - 基本的には音声のような時系列情報を扱うため、RNNやLSTMのような時系列を考慮したDNNを用いる。
- CTCにおける重要な発明は次の2点。
  - ブランク（冗長ラベル）の導入
    - ブランクを導入する理由は大きく2つ
    - １つは、同一ラベルが連続するテキスト系列を表現するため
      - ブランクが存在しない場合、例えば[a, a, a, a, b, b, b]は[a, b]に縮約されてしまうため、[a, a, b]を表現することができません。連続するラベルの間に[a, a,, a, a, b, b]のようにブランクが挿入されることにより、同一ラベルが連続するようなテキスト系列も表現できるようになります。
    - もう1つの理由は、厳密にアライメントを決定させないため。
      - 音素の境界は曖昧なことも多く、また単語の間にはポーズ(間)などの非音声区間も存在します。そのようなフレームに対しても何らかのラベルを無理やり割り当てようとすると、音声認識にとって最適ではないモデルが学習される可能性があります。そこで、該当するラベルがないことを意味するブランクの出力を許可することで、モデルが無理なアライメント推定を行わずに音声認識結果が正解することのみを目的とした学習を可能にしています
  - 前向き・後ろ向きアルゴリズム(forward-backward algorithm)を用いたDNNの学習
- 8フレームの音声系列の例で、最終的なテキスト列が[a, b, c]となるようなRNNの出力は[a,, b, b, b, c,,]、[,, a,, b, b,, c]など沢山存在します。
- つまり、入力音声系列\\\(x^9\\\)に対して縮約後の出力テキスト系列がl= [a; b; c]となる事後確率は、
  > \\\(\begin{aligned}P(l\|x) &= P([a,-,b,b,b,c,-,-]\|x) + P([-,-,a,-,b,b,-,c]\|x) + \cdots \cr
  &=\sum_{\pi = \Beta^{-1}(l)} P(\pi\|x)
  \end{aligned}\\\)
- \\\(P([a,-,b,b,b,c,-,-]\|x)\\\)は入力xに対してRNNの(縮約前の)出力が[a,-,b,b,b,c,-,-]となる確率を表します。また \\\(\Beta^{-1}(l) \\\) は「縮約するとテキスト系列lになるような縮約前のラベル系列の集合」を表しています。この集合に含まれるラベル系列は、[a,-,b,b,b,c,-,]、[-,-,a,-,b,b,-,c]など複数存在するため、それら全てを足し合わせるということを上式は意味している。音声認識モデルは、このP(l|x)が最大となるようなテキスト系列lを音声認識結果として出力する。
- 学習の際は、正解テキスト系列\\\(l^*\\\)における確率\\\(P(l^*\|x)\\\)が最大となるようにRNNのパラメータ調整を行うことになる。よって、CTCにおいて最小化すべき損失関数は、この事後確率P(l|x)の対数に1をかけたもの。
  - \\\(L_{CTC} = - \log P(l^* \| x)\\\)
- \\\(P(l^*\|x)\\\)を計算することは、縮約すると\\\(l^*= [a; b; c]\\\)となる全てのパスの確率を足し合わせることに対応します。それぞれのパスの確率自体は、パス上で各ラベルが出力される確率の積として簡単に計算できる。
- しかし、縮約して\\\(l^* = [a; b; c]\\\)となるパスは大量にあるため、全てを愚直に計算するのは非効率。そのため実際のCTCでは、より効率的な計算方法である前向き・後ろ向きアルゴリズム(forward-backward algorithm)が用いられます。
- 前向き確率\\\(\alpha_t(s)\\\)
  - 始点からフレームt、拡張ラベルsの頂点に到達するまでの全パスの確率の総和
  > \\\(\displaystyle \alpha_t(s) \equiv \sum_{B(\pi_{1:t})=l_{1:[s/2]}^*} \prod_{t^\prime = 1}^t y_{\pi_{t^\prime}}^{t^\prime}\\\)
- 後ろ向き確率\\\(\beta_t(s)\\\)
  - フレームt、拡張ラベルsの頂点から終点まで到達する全パスの確率の総和
  > \\\(\displaystyle \beta_t(s) \equiv \sum_{B(\pi_{1:t})=l^*_{[s/2]:\|l^*\|}} \prod_{t^\prime = t}^T y_{\pi_{t^\prime}}^{t^\prime}\\\)
- \\\(l_{i:j}\\\)は、成分iから成分jまでを持つベクトル(系列)を表しています。[]はガウス記号（中の数値の値を超えない最大の整数）を表す。
- \\\(B(\pi_{1:t})=l^*_{1:[s/2]}\\\)はt=4,s=4の時、
- 「縮約するとラベル系列[a, b]となるフレーム1~4の頂点を通るパス\\\(\pi_{1:4}\\\)の集合を表している。
- 前向き確率と後ろ向き確率を掛け合わせて計算を実施すると、次式が導ける。

> \\\(\displaystyle P(l^*\|x) = \sum_{s=1}^{\|l^*\|} \frac{\alpha_t(s)\beta_t(s)}{y_{l_s^*}^t}\\\) (for any t) 

- つまり\\\(P(l^*\|x)\\\) そしてCTC損失関数 \\\(L_{CTC}=logP(l^*\|x)]\\\)を計算するためには、前向き確率と後ろ向き確率さえ用意すればよい。

# CTCによる音声認識

- シンプルな方法としてbest path decoding、よりより複雑なコーディングとして、best search decodingが考案されている。

