<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[['\$','\$'],['\\(','\\)']],processEscapes:true},CommonHTML: {matchFontHeight:false}});</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

# 音声認識タスク
- 音声認識(ASR: Automatic Speech Recognition)とは、入力信号を音声特徴ベクトルに変換、その音声特徴ベクトルの系列から対応する単語列を推定するタスクです。
- まず、入力された音声信号を認識処理にとって都合の良い表現に変換します。この処理のことを特徴量抽出と呼びます。主にフーリエ変換などが実施される。
- 次に、認識の部分で音声認識結果の候補の確率を計算します。（音声認識モデル）
- 現在の音声認識モデルは音響モデル、発音辞書、言語モデルの3つの部分から構成されており、それぞれ以下の役割を担っています。
  - 音響モデル
    - 音声特徴量と音素列の間の確率を計算するモデル。
  - 発音辞書
    - 音素列と単語との対応を扱うモデル。
  - 言語モデル
    - ある単語に対して、その単語が発話される確率を計算します。
- 音響モデルについては、1980年代から2010年ごろまでの長い間、隠れマルコフモデル(HMM: hidden Markov model)と混合正規分布(GMM: Gaussian mixture model)と呼ばれるモデルを組み合わせることでモデル化されていました。それが2010年ごろから深層学習技術の発展に伴い、混合正規分布がディープニューラルネットワーク(DNN: Deep Neural Network)に置き換わることで音声認識精度が飛躍的に向上し、多くの製品で使われる音声認識モデルとなっています。
- 1つ大きな問題があります。それは直感的には非常に理解しやすい構造なのですが、実際に実装する際には非常に複雑になってしまう点です。特に、3つのモジュールの出力をうまく統合して音声認識結果を出力する「デコーダ」と呼ばれる処理部分の実装が難しく、音声認識モデルを実装する上で高いハードル
- 2015年ごろからは音響モデル、発音辞書、言語モデルを1つのDNNで表現する、いわゆるEnd-to-Endモデル(E2Eモデル)の研究が盛ん
  - その一つがCTC

# CTC