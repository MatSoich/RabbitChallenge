<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[['\$','\$'],['\\(','\\)']],processEscapes:true},CommonHTML: {matchFontHeight:false}});</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

# 勾配降下法
- 誤差関数を最小にする、重み（w）とバイアス（b）を探索する方法の１つ
- 学習率を調整して、前回の学習内容を適切に次の学習に反映させることが重要
# 確認テスト９
- 勾配降下法のソースコードを抜き出す。
```python
    # パラメータに勾配適用
    for key in ('W1', 'W2', 'b1', 'b2'):
        network[key]  -= learning_rate * grad[key]
```
# 学習率決定のためのアルゴリズム
- Momentum, Adagrad, Adadelta, Adamなど。
- Adamが最も有名。
- 詳細はDay2で実施。

# 確率的勾配降下法
